{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_health_mse_rmse_w5day.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShangWeiKuo/106-2-R-project/blob/master/Code/ResearchMethod/health/5day/LSTM_health_mse_rmse_w5day.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvu9sWT5-1Zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774da054-187e-4ea2-8812-a3e0a90dc995"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LSk9WVOlZJJ"
      },
      "source": [
        "from math import sqrt\n",
        "import numpy as np\n",
        "from numpy import concatenate, hstack\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat, Timestamp\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU, LeakyReLU\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers import Bidirectional\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "import os\n",
        "import matplotlib.dates as mdates\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2voLi8TlT8IB"
      },
      "source": [
        "# 引進中文字體檔案\n",
        "import matplotlib.font_manager as fm\n",
        "path = os.path.join(os.getcwd(), '/content/drive/MyDrive/paper/SimHei.ttf')\n",
        "fontprop = fm.FontProperties(fname=path, size=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHW3v7rBoH9S"
      },
      "source": [
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(0)\n",
        "python_random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-JjHcwcoK7v"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto(\n",
        "      intra_op_parallelism_threads=1,\n",
        "      inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=session_conf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yXB6jNqoOC0"
      },
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8B3IqmUoSHW"
      },
      "source": [
        "# 數據預處理\n",
        "path = os.path.join(os.getcwd(), '/content/drive/MyDrive/paper/raw_covid_data_v2.csv')\n",
        "dataset = read_csv(path, index_col=0)\n",
        "dataset.index.name = \"Datetime\"\n",
        "dataset.index = pd.to_datetime(dataset.index)\n",
        "dataset = dataset[['new_case', 'positive', 'death', 'new_test']]\n",
        "values = dataset.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgSgouU1vJdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23df45a6-95c5-4387-8a71-ded5d54f17b8"
      },
      "source": [
        "dataset.values.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(414, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAzQ8SDIY9gv"
      },
      "source": [
        "n_days = 5\n",
        "n_features = 4\n",
        "\n",
        "reframed = series_to_supervised(values, n_days, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzsJohePoUoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ee4d5d-245f-48dd-f41b-31eec09f1d3b"
      },
      "source": [
        "# 標準化\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "\n",
        "# 轉成監督式數據\n",
        "reframed = series_to_supervised(scaled, n_days, 1)\n",
        "print(reframed.shape)\n",
        "\n",
        "# 數據準備\n",
        "values = reframed.values\n",
        "\n",
        "# 劃分訓練數據與測試數據 (Train:80%, Test:20%)\n",
        "n_obs = n_days * n_features\n",
        "train = values[:331, :]\n",
        "test = values[331:, :]\n",
        "\n",
        "# Split into inputs and outputs\n",
        "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
        "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
        "print(train_X.shape, len(train_X), train_y.shape)\n",
        "\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], n_days, n_features))\n",
        "test_X = test_X.reshape((test_X.shape[0], n_days, n_features))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "\n",
        "# Early Stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "\n",
        "# 建模 - 8 layers\n",
        "model_8 = Sequential()\n",
        "model_8.add(LSTM(200, activation='tanh', return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "# model_8.add(LeakyReLU())\n",
        "model_8.add(LSTM(200, activation='tanh', return_sequences=True))\n",
        "model_8.add(LSTM(200, activation='tanh', return_sequences=True))\n",
        "model_8.add(LSTM(200, activation='tanh', return_sequences=True))\n",
        "model_8.add(LSTM(200, activation='tanh'))\n",
        "model_8.add(Dense(1))\n",
        "model_8.compile(optimizer='adam', loss='mse')\n",
        "model_8.summary()\n",
        "# fit network\n",
        "history = model_8.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=10, batch_size=32, verbose=2,\n",
        "                    shuffle=False, callbacks=es)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(409, 24)\n",
            "(331, 20) 331 (331,)\n",
            "(331, 5, 4) (331,) (78, 5, 4) (78,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 200)            164000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 200)            320800    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 5, 200)            320800    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 5, 200)            320800    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 1,447,401\n",
            "Trainable params: 1,447,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "11/11 - 26s - loss: 0.0384 - val_loss: 0.1209\n",
            "Epoch 2/10\n",
            "11/11 - 1s - loss: 0.1204 - val_loss: 0.0111\n",
            "Epoch 3/10\n",
            "11/11 - 1s - loss: 0.0385 - val_loss: 0.0159\n",
            "Epoch 4/10\n",
            "11/11 - 1s - loss: 0.0389 - val_loss: 0.0028\n",
            "Epoch 5/10\n",
            "11/11 - 1s - loss: 0.0110 - val_loss: 0.0048\n",
            "Epoch 6/10\n",
            "11/11 - 1s - loss: 0.0386 - val_loss: 0.0023\n",
            "Epoch 7/10\n",
            "11/11 - 1s - loss: 0.0237 - val_loss: 0.0024\n",
            "Epoch 8/10\n",
            "11/11 - 1s - loss: 0.0656 - val_loss: 0.0118\n",
            "Epoch 9/10\n",
            "11/11 - 1s - loss: 0.0417 - val_loss: 0.0035\n",
            "Epoch 10/10\n",
            "11/11 - 1s - loss: 0.0194 - val_loss: 0.0154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C97u6DedoffT"
      },
      "source": [
        "# make the prediction_8\n",
        "testPredict_8 = model_8.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], n_days * n_features))\n",
        "\n",
        "# inverse the prediction_8\n",
        "inv_testPredict_8 = concatenate((testPredict_8, test_X[:, -(n_features - 1):]), axis=1)\n",
        "inv_testPredict_8 = scaler.inverse_transform(inv_testPredict_8)\n",
        "inv_testPredict_8 = inv_testPredict_8[:, 0]\n",
        "\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_ytest = concatenate((test_y, test_X[:, -(n_features - 1):]), axis=1)\n",
        "inv_ytest = scaler.inverse_transform(inv_ytest)\n",
        "inv_ytest = inv_ytest[:, 0]\n",
        "\n",
        "PredictionData = inv_testPredict_8\n",
        "TrueData = inv_ytest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4MgGhuw4LaJ"
      },
      "source": [
        "pd.DataFrame(PredictionData).to_csv(\"/content/drive/MyDrive/paper/health/MSE_PredictionData_Test_health_w5day.csv\")\n",
        "pd.DataFrame(TrueData).to_csv(\"/content/drive/MyDrive/paper/health/MSE_TrueData_health_w5day.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}